---
title: "Methods for processing censored data FV3"
author: "Marc Roddis"
date: "7/17/2020"
output: pdf_document
fontsize: 12pt
geometry: margin=1.5in
---

```{r chunk1, include=FALSE}
library(RCurl)
library(tidyverse)
library(styler)
library(gridExtra)
library(cowplot)
library(truncreg)
library(truncnorm)
library(censReg)
load("AllTablesPredsGraphsv18e.Rdata")
knitr::opts_chunk$set(echo=FALSE)
```

## Introduction

The Swedish National Monitoring Programme for Contaminants (SNMPC) in freshwater biota has various goals and large scope (citation needed).    

Our main goal in this study was to explore the viability of alternative methodologies for parameter estimation from censored data and to compare these alternatives with the methodology used by SNMPC. 

Censored data is very common in environmental chemistry so our research area has been researched extensively by others.  We will select well-regarded methods and apply these according to best practice, according to the cited works (citation needed). 

At the outset, we limited the scope of our study by choosing to focus on the estimation of long-term time trends for the concentration of polychlorinated biphenyls (PCBs) in biological samples.  

Our main idea was that since PCBs have similar chemical and physical properties their concentrations may be correlated such that censored measurements can be imputed using censored regression.  

Our idea is supported by the SNMPC dataset since it has no censored data for CB153, whereas 34 % of the data for CB28 is censored.  

More importantly, our exploratory data analysis of SNMPC data showed that CB153 and CB28 concentrations are strongly correlated.

Moreover, CB153 and CB28 also show a very similar rate of decrease over the time period 2003-2017.

Concretely, our idea is to impute censored CB28 values from the corresponding uncensored observations for CB153. 

The resulting "imputed datasets" could then be used to obtain better parameter estimates than from the methodology currently used by SNMPC, which uses "substituted datasets" instead.  

Specifically, SNMPC substitute all censored data by $\frac{LOD}{\sqrt{2}}$.

#### Our workflow

We now present an eight-step overview of our workflow in this section.  We will give a more detailed description of steps 1-7 in the subsequent sections.

1. Selection of a set of parameter values, and generation of the simulation dataset accordingly.

2.  Estimation of $\beta$ from the simulation dataset by simple linear regression to get a benchmark to compare other methods against.

3.  Selection of the proportion $\texttt{cprop}$ of CB28 values to censor, and generation of the censored dataset accordingly.

4.  Creation of a "completed dataset" by replacing censored data using some or all of our six methods.  The completed datasets created by different methods will be distinct. 

5.  Estimation of $\beta$ from each completed dataset by simple linear regression (by the same procedure as Step 2).

6.  Estimation of $\beta$ directly from the censored dataset by censored regression.

7.  Presentation of the MSE, squared-bias, and variance, of the estimates from each method.

8.  Repetition of steps 1-7 for various selections of parameter values.

9.  Discussion of all results.


 


### Model selection for generation of our simulation datasets

We begin by performing exploratory data analysis and model fitting from datasets from the SNMPC.

We do this in order to design our simulation studies to have real real-world relevance.

A large dataset `pcb.csv` was provided from SNMPC.

This dataset has 5056 observations of 18 variables; these variables include: measured concentrations of seven PCBs (CB28, CB53, CB101, CB118, CB138, CB153, CB180); year (1984-2017); an ID for each observation; and nine other variables such as species and age.    


Our exploratory data analysis showed that 

1. The most recent 15-year period 2003-2017 had sufficient relevant data, so we will focus solely on this time period.

2. It is reasonable to model the observed pcb concentrations as log-normal distributed.

3. The data for CB153 had no censored values, whereas CB28 data had the highest proportion of censored values.  This proportion was 0.34.

4. Species is clearly a confounding variable for the association between CB153 and CB28, so we will focus solely on herring (since this was the species for which there were most observations).  No other variable showed clear evidence for confounding.

From this basis, we create our test dataset from the original dataset `pcb.csv` by omitting all missing values of `CB28` and `CB153`, removing all observations except those from herring species, removing all observations prior to 2003, re-indexing 2003 as "year zero", removing all variables except `YEAR`, `CB28` and `CB153`, and omitting all censored observations. 

We fit linear regression models to our test dataset for $y=CB28, x=CB153$ and for $y=log(CB28), x=log(CB153)$; the adjusted R-squared values were 0.93 and 0.96 respectively.  

Based on this, we decide we will use logarithmised concentrations throughout, which we will model as normally distributed.

We have three variables $log(CB28)$,  $log(CB153)$, and $YEAR$; we will denote these as $Y$, $X$ and $A$ respectively, throughout the rest of our work.  

We make the key observation that $Y$ and $X$ are strongly correlated in our test dataset, which means that our key idea of using censored regression for $Y$ on $X$ to make imputations for censored $Y$ values is plausible.

We also fit a model to our test dataset for the regression $X$ on $A$, which gave

$$E(X|A) = -2.91 - 0.02A$$


the corresponding fitted model for $Y$ on $X$ is $$E(Y|X) = -3.18 + 0.79X$$

the residual standard error was equal to $0.1$ from both models.

From this basis, we will generate our simulation datasets as follows:  

1.  We will also always simulate a 15-year period; we will use $A \in \{0, 1, 2, ..., 14\}$ to denote year.

2. For every year, we will generate the same number of observations for $Y$ and $X$, we will call this number the sample size $N$.   For our first simulation we will use $\texttt{sample size}=100$ because there are typically 100 observations on herring each year by the Monitoring Program.   

3. We generate all $x_{i}$ from  $$x_{i} = -2.91 - \beta_{A}a_{i} + e_{i}$$ 

where $i \in \{1, 2, ..., N\}$ denotes the ith observation, and the noise is modeled as normally distributed with $mean=0$ and $variance=0.1^{2}$, i.e. $e_{i} \sim N(0, 0.1^{2})$.

We will be interested in evaluating our methods for various values of $\beta_{A}$, so this will be a variable parameter for our simulations.

4. We generate all $y_{i}$ from $$y_{i} = -3.18 + 0.79x_{i} + \epsilon_{i}$$ 

where $\epsilon_{i} \sim N(0, \sigma^{2})$.

We will be interested in evaluating our methods for various values of $\beta_{A}$ and $\sigma^{2}$, so these will be the two variable parameters for our simulation datasets.


#### Estimation of $\beta$ from the simulation dataset by simple linear regression

The main body of our work will be to evaluate various methods for the estimation of the regression coefficient $\widehat{\beta}$ for datasets containing censored values. 

In this section, we will instead assume that there are no censored values, which allows us to find estimates by simple linear regression.  

We will later use these estimates as the benchmark for evaluating the methods we use in the main body of our work. 

Our primary goal is to find $\widehat{\beta}$, which means we will find estimates for $\beta$ where $Y_{i} = \alpha + \beta a_{i} + \varepsilon_{i}$.

To specify this model, we first substitute

$$x_{i} = -2.91 - \beta_{A}a_{i} + e_{i}$$

nto

$$y_{i}^{*} = -3.18 + 0.79x_{i} + \epsilon_{i}$$

which gives

$$y_{i}^{*} = -3.18 + 0.79(-2.91 - \beta_{A}a_{i} + e_{i}) + \epsilon_{i}$$

$$= -3.18 + 0.79-2.91 - 0.79\beta_{A}a_{i} + 0.79e_{i} + \epsilon_{i}$$

$$= \alpha + \beta a_{i} + \varepsilon_{i}$$

where $\alpha = -3.18 + 0.79 \times -2.91 = -5.4789$, and $\beta = 0.79\beta_{A}$. 

Also $\varepsilon_{i} = 0.79e_{i} + \epsilon_{i}$, where $e_{i} \sim N(0, 0.1^{2})$ and $\epsilon_{i} \sim N(0, \sigma^{2})$. 



#### Creation of datasets with censored values 

For our simple linear regression of $Y$ on $X$ we used $y_{i} = -3.18 + 0.79x_{i} + \epsilon_{i}$, where $\epsilon_{i} \sim N(0, \sigma^{2})$.

We now use $y_{i}^{*}$ instead of $y_{i}$, where $y_{i}^{*}$ refers to the ith observation prior to it being observed.

This means that after $y_{i}$ has been observed and left-censoring at $LOD$ has been applied, we have  $y_{i}= y_{i}^{*} \text{   if   } y_{i}^{*}>LOD$ and  $y_{i}= LOD \text{   if   } y_{i}^{*} \leq LOD$.

We will determine $LOD$ by censoring a fixed proportion, which we denote as $cprop$, of all observed $y_{i}$ values, for each of our simulations.  

We will be interested in evaluating our methods for various values of $cprop$, which is our variable parameter of primary interest.

Moreover since $LOD = cprop * 100$th percentile of all $y_{i}$ values, the value of $LOD|cprop$ is constant and thus independent of $A$.

Our primary goal is to find $\widehat{\beta}$, which means we will find estimates for $\beta$ where $Y_{i} = \alpha + \beta a_{i} + \varepsilon_{i}$.


####  Creation of a "completed dataset" by replacing censored data using some or all of our six methods

We view every censored observation as having a true but unknown value within the interval $[0, LOD]$.

Our goal is to replace all such unknown values with a known value such that the resulting values are as close to the true values as possible.

The most straightforward way to this is by substitution, which means that all censored values from a censored dataset are substituted by the same fixed value, which is a fraction of $LOD$.  

The monitoring program that motivates our work uses substitution by $\frac{LOD}{\sqrt{2}}$, which is the most commonly used value based in the research literature cited in this report.  

The second most commonly used value is $\frac{LOD}{2}$.  

The largest possible value that can be used for substitution is $LOD$, since all of the censored values  are known to lie within the interval $[0, LOD]$.

Our three substitution methods will use substitution by either $LOD$, $\frac{LOD}{\sqrt{2}}$ or $\frac{LOD}{2}$; we name them  $\texttt{subst1}$, $\texttt{subst2}$, and $\texttt{subst4}$, respectively.  
Our notation is based on the fact that $LOD = \frac{LOD}{1}$, and that $2 = \sqrt{4}$ and $1 = \sqrt{1}$, respectively. 

Our rationale for choosing these three methods is that since $\frac{LOD}{2} < \frac{LOD}{\sqrt{2}} < LOD$ we can compare results from the $\texttt{subst2}$ method that SNMPC uses with two alternative substitution methods, which use substitution by lower and higher values, respectively.

However, such substitution methods are limited since they do not use observations from other variables of the dataset.

Our conjecture is that we can use censored regression to impute censored $y_i$ values from the corresponding uncensored $x_i$ values, thus leveraging the strong correlation between the $Y$ and $X$. 

We call our main imputation by censored regression method $\texttt{censReg1}$ , because it is based on a censored regression model with $1$ predictor variable $X$, as described in the following section.  

##### Creation of completed datasets by censored regression by our main method $\texttt{censReg1}$

Each observation $y_{i}^{*}$ is from a normal distribution with mean  $\mu_{i_{X}} = \alpha_{X} + \beta_{X}x_{i}$ and variance $\sigma^{2}$, which has pdf

$$f(y_{i}^{*}) = \frac{ exp[(-1/2)( (y_{i}^{*}-\mu_{i_{X}}) / \sigma)^{2}]}{\sigma\sqrt{2\pi} } $$

which we can write as 

$$f(y_{i}^{*}) = \frac{\phi( (y_{i}^{*}-\mu_{i_{X}}) / \sigma) } {\sigma } $$


where $\phi$ is the pdf of a normal distribution with $mean=0$ and $variance=1$.

The probability that $y_{i}^{*}$ is censored equals 

$$P(y_{i}^{*} \leq LOD) = \Phi( (LOD-\mu) / \sigma)$$

where $\Phi$ is the cdf of a normal distribution with $mean=0$ and $variance=1$.

Every $y_{i}^{*}$ is either censored or not, so we will use the indicator variable $I=1$ for censored, and $I=0$ for not censored.  Moreover, we assume that $y_{i}$ are all independent, which means that the joint likelihood over all observations is the product of the density functions for all  $y_{i}$.  

This gives us the likelihood function L

$$ L = \prod_{i=1}^{A}[[ (1/\sigma) \phi( (y_{i}-\mu_{i_{X}}) / \sigma) ] ^{1-I} \times \Phi( (LOD-\mu_{i_{X}}) / \sigma)^{I}] $$
So the log-likelihood function is 

$$\log(L) = \sum_{i=1}^{A}[(1-I) [\log( \phi( (y_{i}-\mu_{i_{X}}) / \sigma) ) - \log(\sigma)]  + I \times \log[  \Phi( (LOD-\mu_{i_{X}}) / \sigma) ]] $$
which equals

$$\log(L) = \sum_{i=1}^{A}[(1-I) [\log( \phi( (y_{i}-(\alpha_{X} + \beta_{X}x_{i}) ) / \sigma) ) - \log(\sigma)]  + I \times \log[  \Phi( (LOD-(\alpha_{X} + \beta_{X}x_{i}) ) / \sigma) ]] $$

We will use the $\texttt{censReg()}$ function from the censReg package in R to maximise this log-likelihood function to obtain the maximum likehood estimates $\widehat {\alpha_{X} }$, $\widehat {\beta_{X} }$ and $\hat {\sigma }$.

We will then perform imputation as follows.  

Every censored value $y_{i}$ is substituted by the expected value of a truncated normal distribution, which we describe as originating from a normal distribution with $mean =  \widehat \mu_{i_{X}} = \widehat {\alpha}_{X} + \widehat {\beta}_{X}x_{i}$, $variance = \sigma^{2}$, and with truncation at $y = LOD$.  

In our practice, we used the $\texttt{etruncnorm()}$  function from the $\texttt{truncnorm}$ R package to calculate every such expected value.   

We will use the term "completed dataset" for every dataset that results from imputation or substitution. 

  
#### Variations on the $\texttt{censReg1}$ method

We will also use two methods that are closely related to $\texttt{censReg1}$  for the purpose of comparison; we call these methods $\texttt{censReg1naive}$ and $\texttt{censReg2}$.

##### The $\texttt{censReg1naive}$ method

The only difference from $\texttt{censReg1}$ in our $\texttt{censReg1naive}$ method is that the latter uses the corresponding non-truncated normal distribution rather than the truncated one.  Our conjecture is that estimates of $\beta$ from $\texttt{censReg1naive}$ will have significantly higher bias than the corresponding estimates from $\texttt{censReg1}$.  Our rationale is that the censored $y_{i}$ values could be substituted by values that are higher than $LOD$, whereas the true value is known to be not higher than $LOD$.

$\texttt{censReg1naive}$ is the same as $\texttt{censReg1}$ except that a non-truncated normal distribution is used in the imputation step.  We conjecture that this will result in estimates with higher bias than from $\texttt{censReg1}$.  This was done to check that we get a more biased estimate because it is possible that the imputed values are above LOD, despite the fact that the censored value are below LOD.

##### The $\texttt{censReg2}$ method

$\texttt{censReg2}$ uses two predictor variables $X$ and $N$.  

We conjecture that using one additional redundant predictor variable will result in estimates with higher variance than from $\texttt{censReg1}$.  

The mathematical formulation for this method corresponds to that presented above for $\texttt{censReg1}$, except that we model each observation $y_{i}^{*}$ as from a normal distribution with mean  $\mu_{i_{X,A}} = \alpha_{X, A} + \beta_{X}x_{i} + \beta_{A}a_{i}$ and variance $\sigma^{2}$.

This means that the likelihood function for $\texttt{censReg2}$ will have the same form as that for $\texttt{censReg1}$; it will differ only in having $\mu_{i_{X,A}}$ in place of  $\mu_{i_{X}}$.

Consequently, maximisation of the corresponding log-likelihood function gives the maximum likehood estimates $\widehat {\alpha_{X} }$, $\widehat {\beta_{X} }$, $\widehat {\beta_{X} }$ and $\hat {\sigma }$.

Therefore, every censored value $y_{i}$ is substituted by the expected value of a truncated normal distribution, which we describe as originating from a normal distribution with $mean =  \widehat \mu_{i_{X,A}} = \widehat {\alpha}_{X} + \widehat {\beta}_{X}x_{i} + \widehat {\beta}_{A}a_{i}$, $variance = \sigma^{2}$, and with truncation at $y = LOD$. 

#####  Estimation of $\beta$ directly from the censored dataset by censored regression by the $\texttt{censReg0impute}$ method

This method differs from $\texttt{censReg1}$ in the choice of predictor variable for the model for the maximum likelihood estimation step.  

We have seen that the $\texttt{censReg1}$ method uses $X_{i}$ as the predictor for this step.  

The $\texttt{censReg0impute}$ method uses $A_{i}$ as the predictor instead for this step.  

Thus the estimate $\widehat {\beta_{A} }$ is found directly from the maximisation of the corresponding log-likelihood function, without any imputation step.

We conjecture that since $|\beta_{X}|=0.79$ is much greater than $|\beta_{A}|$, $\texttt{censReg0impute}$ will result in estimates with higher variance than from $\texttt{censReg1}$.

## Results

#### Estimation of the regression coefficient `beta28year`

Our first goal will be to screen our 11 methods for the estimation of `beta28year` to determine which methods we will use in our main analysis in a later section.   We will assess these estimates from their MSE, squared-bias and variance in each case.  

We first choose parameter values for this screening study: cprop = 0.3, beta153year = -0.02, sd28_153= 0.3.  These values for cprop and beta153year are equal to our estimates from our real dataset `pcb.csv`, whereas this value for sd28_153 is equal to the mean of two estimates: one which is unconditional, and a second which is conditional on the variable `year`. 

##### Evaluation of methods for smaller sample sizes

We will first obtain results from datasets with different sample sizes in order to decide an appropriate sample size for all our subsequent work.    Our real dataset has approximately 100 observations per year for CB28 and CB153 from herring in years 2003-2017.  However these observations are from various locations and have differences for various other variables such as age, fat-percentage etc., which means that any statistical analysis which controls for such variables would have a smaller sample size.  We will test sample sizes that differ by a factor of 2:  we do this by generating datasets by simulation using 10000 iterations, with sample sizes 50, 25, 12 and 6 respectively.   The squared-bias of the estimates of `beta28year` from all 11 methods and all 4 sample sizes is shown below; note that all values shown in the table are 100000 times bigger than the actual values (to make them easier to read and compare).  The column names `bias_ss50`, `bias_ss25`, ... denote sample sizes 50, 25, ... respectively. 

```{r chunk10a2}
round(beta_table_all11_cprop03_beta002_ss25_sd03_niter10000*100000, 5)
round(beta_table_all11_cprop03_beta002_ss12_sd03_niter10000*100000, 5)
round(beta_table_all11_cprop03_beta002_ss6_sd03_niter10000*100000, 5)
round(bias_all_ss_df*(10^7), 4)
```

The following table below is the same as the previous one, except that it shows the variance of the estimates. 

```{r chunk10b2}
round(beta_table_all11_cprop03_beta002_ss25_sd03_niter10000*100000, 5)
round(beta_table_all11_cprop03_beta002_ss12_sd03_niter10000*100000, 5)
round(beta_table_all11_cprop03_beta002_ss6_sd03_niter10000*100000, 5)
round(variance_all_ss_df*(10^7), 4)
```

Allowing for random error from using only 10000 iterations, we can conclude that the squared-bias is independent of sample size, whereas the variance is inversely proportional sample size.  Moreover since the bias_variance decomposition $ MSE = Bias^2 + Variance$, always holds, we need not look at the MSE values for the purpose of choosing sample size.  

We find in additional experiments (details not shown) that the standard error of the estimates is inversely proportional to the square root of the number of simulation iterations, so we have three factors to balance: 

1. We want our results to be potentially applicable for real data.

2. We want sample size to be sufficiently large to avoid MSE being dominated by variance alone.

3. We want the number of iterations to be sufficiently large that our estimates have sufficiently low standard error.

We therefore decide to use sample size = 12 for all of our subsequent experiments.


```{r chunk12b}
round(beta_table_all11_cprop03_beta002_ss50_sd03*100000, 5)
round(beta_table_all11_cprop03_beta002_ss25_sd03*100000, 5)
round(beta_table_all11_cprop03_beta002_ss12_sd03*100000, 5)
round(beta_table_all11_cprop03_beta002_ss6_sd03*100000, 5)

```

##### Selection of censoring methods for further study

We will now use simulations with just 1000 iterations for all 10 methods (and also for our reference method `best`) to estimate `beta28year` for four sets of parameter values: 

beta28year = -0.02 is held fixed.

a "low" and a "high" value for each of `cprop` and `sd28_153` are used.  Concretely: (0.1, 0.1), (0.7, 0.1), (0.1, 0.5) and (0.7, 0.5) were used for (cprop, sd28_153) respectively.

The following four tables show the MSE, squared-bias, and variance of estimates of `beta28year` from all 11 methods, for the four sets of parameter values, respectively.

We see that there is a much bigger difference between different methods in the amount of bias than in the amount of variance.   We will therefore focus primarily on the results for bias; we will use terms such as high and low to compare the bias from different methods.  We see that the amount of bias for:

`best` serves as a reference value; a gold standard that we compare the other methods with.

`omit` is high for (0.1, 0.1) and (0.1, 0.5), and is very high for (0.7, 0.1) and (0.7, 0.5).  It makes sense that there is higher bias with higher proportion of censored values since a higher proportion of the data has been omitted.  Moreover, these generally high values are commensurate with our prior expectations (ref: Helsel's book) that `omit` is a poor method, so we will not study this method further.

Very high for: `subst1` for (0.7, 0.1) and (0.7, 0.5); `subst2` for (0.7, 0.5); `subst4` for (0.1, 0.1) and (0.7, 0.1).  However, all three substitution methods also have low bias for at least one set of parameter values.  This is intriguing and merits further investigation.

Very low for: `censReg1`, `censReg2` and `censReg0impute` for all four parameter value sets.

Highest of all four censReg methods for all four parameter sets for `censReg1naive`. This illustrates the necessity of conditioning on both the cb153 value and the condition cb28 < cb28_cprop by using a truncated normal distribution, and verifies the results we presented in our previous chapter on mathematical theory.    `censReg1`, `censReg2` and `censReg0impute` all do this, whereas in contrast, `censReg1naive` conditions solely on the cb153 value, and thus uses a (non-truncated) normal distribution;  this results in significant bias because cb28 values can be erroneously imputed to be higher than `cb28_cprop`.   Consequently we will not discuss censReg1naive any further: it has served its purpose in showing the importance of conditioning oth the cb153 value and the condition cb28 < cb28_cprop.


The hybrid methods `subst2lmimpute` and `omitlmimpute` 
first use substitution and omission as in `subst2` and `omit` respectively,  followed by imputation.  Therefore  `subst2lmimpute` should be compared with `subst2`, and `omitlmimpute` with `omit`.  `subst2lmimpute` has higher bias (and also MSE) than `subst2` for all parameter value sets, and `omitlmimpute` has higher bias than `omit` for all sets except (0.1, 0.5).  We have already rejected the `omit` method so we must also reject `omitlmimpute` since it performs no better than `omit`.  Similarly we reject `subst2lmimpute`, since this method performed worse than `subst2` in all four cases.

In summary, we have rejected 4 of our 10 methods.  We will limit our attention to six methods for all our subsequent work: the three substitution methods `subst1`, `subst2`, `subst4`, and the three censReg methods `censReg1`, `censReg2` and `censReg0impute`.  We will use `best` as our reference method throughout.

```{r chunk12c, eval=FALSE}
round(beta_table_all11_cprop01_beta002_ss12_sd01*100000, 5)
round(beta_table_all11_cprop07_beta002_ss12_sd01*100000, 5)
round(beta_table_all11_cprop01_beta002_ss12_sd05*100000, 5)
round(beta_table_all11_cprop07_beta002_ss12_sd05*100000, 5)
```


#### Evaluation of methods for larger absolute values of `beta28year`

We will now focus our six chosen methods  `subst1`, `subst2`, `subst4`, `censReg1`, `censReg2`, `censReg0impute`.  We will use these methods to estimate `beta28year` from four simulations that use the same parameter values ss = 12, cprop = 0.3, sd28_153 = 0.3, n_iter = 10000 as before.  We will use the four `cb153year` parameter values -0.02, -0.04, -0.08, -0.16 in these four simulations, respectively.  The results from the simulations are shown in the four tables below.

We see that for these parameters value sets, censReg method give estimates that have much lower bias, in general.   The `subst1` method is designed as a reference that gives biased estimates, since it substitutes cb28 values that are observed to be below LOD with the LOD value itself, so the substituted values will always be larger than the real values.  Moreover, we have chosen to maintain a constant LOD level for all years of the same dataset.   We are also simulating cb28 and cb153 data using a linear (degree 1 polynomial) function with a negative slope and a fixed constant (intercept) term. This means that the cb28 values decrease faster with years for larger values of abs(beta153year).  This all means that it is an inevitable consequence of our design that the bias from `subst1` increases as abs(beta153year) increases, which is precisely what we see in these results.    

In contrast, the bias from `subst4` first increases from abs(beta153year) = 0.02 to 0.08 and then decreases for abs(beta153year) = 0.16.  This suggests that since  `subst4` substitutes censored values with $\frac{LOD}{2}$, which are lower than the true values on average for low values of abs(beta153year) but not lower for the highest value abs(beta153year) = 0.16.  This is also supported by the fact that the bias from `subst2` is much lower than that from `subst1` or `subst4`, which suggests that the real values of the censored data mostly lie between $LOD$ and $\frac{LOD}{2}$.

The three censReg methods all give very similar results to one another; the values of MSE, squared-bias and variance are very similar from these methods for both abs(beta153year) = 0.08 and 0.16.  However, for the lowest value abs(beta153year) = 0.02, the variance from `censReg1` is approximately 10% lower than from `censReg2`, which is a statistically significant difference.  This fits with our prior knowledge that a more complex model generally has higher variance than the corresponding less complex one.  Moreover, we also expected that the estimates from `censReg2` would improve relative to those from `censReg1` as the value of abs(beta153year) increases, since the difference between these two methods is that `censReg2`uses `year` as additional predictor variable.  However, the fact that `censReg0impute` has a higher variance than `censReg1` seems puzzling in this respect, so perhaps our interpretation of model complexity is wrong is this context.

Our prior expectation was that `censReg0impute` would perform relatively worse compared to the other `censReg` methods for larger values of abs(beta153year).  This is because we conjecture that the imputations from the predictor variables carry more information about cb28 as the absolute value of `beta28year` increases, and `censReg0impute` does not use imputation at all.  However, these results fail to support our conjecture here too.

If we now compare the best performing models from each category, i.e. `subst2` and `censReg1`, we see that `censReg1` has much lower bias for all parameter values.  However, MSE for `subst2` is lower for one of the values, abs(beta153year) = 0.08.  In conclusion, we can say that `censReg1` gives better estimates than `subst2` for most, but not necessarily all, values of abs(beta153year).


```{r chunk13b}

round(beta_table_key7_cprop03_beta002_ss12_sd03_niter10000*100000, 4)
round(beta_table_key7_cprop03_beta004_ss12_sd03_niter10000*100000, 4)
round(beta_table_key7_cprop03_beta008_ss12_sd03_niter10000*100000, 4)
round(beta_table_key7_cprop03_beta016_ss12_sd03_niter10000*100000, 4)

```

#### Evaluation of methods for other values of `sd28_153`

We will now hold `beta28year` and `cprop` fixed at their original values ($-0.02$ and $0.3$) and investigate the effect of larger `sd28_153` values, specifically: 0.1, 0.3, 0.5, and 0.7.  

We see again that for these parameters value sets, censReg method give estimates that have very much lower bias, in general.   Since the three censReg methods all give very similar results to one another and very different results from the three substitution methods, we will again begin by interpreting the results for these two method categories separately.

The bias from `subst4` decreases greatly as the value of `sd28_153` increases, whereas the bias from `subst1` is relatively independent of the value of `sd28_153`.  The bias from `subst2` again follows a trend intermediate between that of `subst1` and `subst4`, since it decreases from sd28_153 = 0.1 to 0.5 and then decreases for sd28_153 = 0.7.  Our interpretation is that since the censored values lie closer on average to LOD for smaller values of sd28_153, and further away for larger values.  The low bias from `subst4` for sd28_153 = 0.7 indicates that the real values for the censored data lie close to $\frac{LOD}{2}$ on average for this parameter value.

The large gap between the uncensored cb28 data and the $\frac{LOD}{2}$ value means that `subst4` gives higher variance than all other methods for all values of sd28_153.   Similarly, the smallest possible gap between $LOD$ and the uncensored cb28 data explains the fact that `subst1` always gives the lowest variance.  We conjecture that the same logic would also hold for other possible substitution values; the larger the gap between this value and LOD, the larger the resulting variance.

Again, we see that the variance from `censReg1` is approximately 10 % lower than that from `censReg2` for all four values of sd28_153.  Surprisingly the results from `censReg2` and `censReg0impute` are almost identical.  Is this a bug?


In conclusion, substitution methods give much higher bias than cenreg methods.  Moreover, all three cenreg methods gave lower MSE than all three substitution methods for both sd28_153 = 0.1 and sd28_153 = 0.3.  However, the variance from cenreg methods increases faster than from substitution methods as sd28_153 increases; in fact for higher values of sd28_153, `subst1` and `subst2` gave the lowest and second lowest MSE values, respectively.  This relative failure of cenreg methods for relatively high values of sd28_153 makes sense, here is our explanation:   A higher `sd28_153` value means that the correlation between cb28 and cb153 is weaker, which results in less accurate imputation by ´censReg1` and `censReg2`, since the accuracy of imputation by these methods relies on the strength of correlation between cb28 and cb153.

```{r chunk14b}

round(beta_table_key7_cprop03_beta002_ss12_sd01_niter10000*100000, 4)
round(beta_table_key7_cprop03_beta002_ss12_sd03_niter10000*100000, 4)
round(beta_table_key7_cprop03_beta002_ss12_sd05_niter10000*100000, 4)
round(beta_table_key7_cprop03_beta002_ss12_sd07_niter10000*100000, 4)

```



#### Further comparisons between `subst2` and `censReg1`

From our previous results, `subst2` is generally the best performing substitution method and `censReg1` is the best censReg method.  In the previous section, these methods gave similar MSE values for sd28_153 = 0.5, so we will fix this parameter at this value and investigate these estimation methods for four values of cprop: 0.1, 0.3, 0.5, 0.7.  These cprop values correspond to censoring 10 %, 30 %, 50 %, and 70% of the data respectively, so they correspond to decreasing values of $LOD$, which is our variable of primary interest.

We see that `censReg1` gives estimates with very low bias for all values of `cprop`, whereas the bias from `subst2` increases greatly as `cprop` increases.   We interpret this as meaning that the real cb28 values are unchanged when LOD is lowered, which means that a higher proportion are likely to lie closer to LOD for larger values of `cprop` which means that substituted values are increasingly biased towards being too small as `cprop` increases.  Since `censReg1` fits a model to all the data (censored and uncensored)  it maintains low bias as the $LOD$ decreases, whilst the variance remains approximately constant.   However, as a greater proportion of values are substituted for the same constant value by the `subst2` method, the variance decreases because a higher proportion of the data values are identical.  

In conclusion, `censReg1` gives similar bias and variance for different values of cprop whereas `subst2` does not.  From `subst2` the bias increases and the variance decreases as `cprop` increases.


```{r chunk15b}
round(beta_table_top3_cprop01_beta002_ss12_sd05_niter10000*100000, 4)
round(beta_table_top2_cprop03_beta002_ss12_sd05_niter10000*100000, 4)
round(beta_table_top2_cprop05_beta002_ss12_sd05_niter10000*100000, 4)
round(beta_table_top2_cprop07_beta002_ss12_sd05_niter10000*100000, 4)

```






#### The MSE, squared-bias and variance of predictions of `cb28` annual means from various censoring methods

All the graphs in this section will shows MSE, squared-bias, or variance on the y-axis and year on the x-axis for the simulated 15-year period.  We begin by looking at variance of predictions from our best three substitution methods, best three censReg methods.  We will again use `best` as our gold standard.

#### Variance of predictions of cb28 annual means from different methods

##### Predictions for different values of beta153year

We will begin by using the same parameter values we used in our earlier section "Evaluation of methods for larger absolute values of `beta28year`".  These parameters are fixed: cprop = 0.3,  sd28_153 = 0.3, whilst cb153year is given four values: -0.02, -0.04, -0.08 and -0.16 respectively. 

We begin by showing graphs of the variance of predictions of cb28 annual means from our chosen censoring methods.  A common feature of all these graphs is that they typically have an approximately parabolic "U" shape, with higher variance at each end of the time period than in the middle of the period.   This is in accordance with our prior expectations because this is generally the case. 


Our first set of four graphs show the variance of `censReg1` and `censReg2` methods relative to `best` method for beta153year equal to -0.02, -0.04, -0.08, -0.16, respectively.   

```{r chunk21}

plot_grid(plot_all_censReg_var_beta002_sd03_cprop03_niter10000, plot_all_censReg_var_beta004_sd03_cprop03_niter10000, plot_all_censReg_var_beta008_sd03_cprop03_niter10000, plot_all_censReg_var_beta016_sd03_cprop03_niter10000, labels = "AUTO")
```

Our second set of four graphs show the variance of `subst1`, `subst2` and `subst4`  methods relative to `best` method for beta153year equal to -0.02, -0.04, -0.08, -0.16, respectively. 

```{r chunk22}

plot_grid(plot_all_subst_var_beta002_sd03_cprop03_niter10000, plot_all_subst_var_beta004_sd03_cprop03_niter10000, plot_all_subst_var_beta008_sd03_cprop03_niter10000, plot_all_subst_var_beta016_sd03_cprop03_niter10000, labels = "AUTO")
```

Our third set of four graphs simply displays the results from the `subst2`, `censReg1` and `best` methods together on the same plot, which is displayed below.

```{r chunk23}

plot_grid(plot_all_var_beta002_sd03_cprop03_niter10000, plot_all_var_beta004_sd03_cprop03_niter10000, plot_all_var_beta008_sd03_cprop03_niter10000, plot_all_var_beta016_sd03_cprop03_niter10000, labels = "AUTO")
```


We will now show graphs of the bias of predictions of cb28 annual means from our chosen censoring methods.

Our first set of four graphs show the bias of `censReg1` and `censReg2` methods relative to `best` method for beta153year equal to -0.02, -0.04, -0.08, -0.16, respectively.  


```{r chunk24}

plot_grid(plot_all_censReg_bias_beta002_sd03_cprop03_niter10000, plot_all_censReg_bias_beta004_sd03_cprop03_niter10000, plot_all_censReg_bias_beta008_sd03_cprop03_niter10000, plot_all_censReg_bias_beta016_sd03_cprop03_niter10000, labels = "AUTO")
```

Our second set of four graphs show the bias of `subst1`, `subst2` and `subst4`  methods relative to `best` method for beta153year equal to -0.02, -0.04, -0.08, -0.16, respectively. 

```{r chunk25}

plot_grid(plot_all_subst_bias_beta002_sd03_cprop03_niter10000, plot_all_subst_bias_beta004_sd03_cprop03_niter10000, plot_all_subst_bias_beta008_sd03_cprop03_niter10000, plot_all_subst_bias_beta016_sd03_cprop03_niter10000, labels = "AUTO")
```

Our third set of four graphs simply displays the results from the `subst2`, `censReg1` and `best` methods together on the same plot, which is displayed below.

```{r chunk26a}

plot_grid(plot_all_bias_beta002_sd03_cprop03_niter10000, plot_all_bias_beta004_sd03_cprop03_niter10000, plot_all_bias_beta008_sd03_cprop03_niter10000, plot_all_bias_beta016_sd03_cprop03_niter10000, labels = "AUTO")
```


We will now show graphs of the MSE of predictions of cb28 annual means from our chosen censoring methods.

Our first set of four graphs show the MSE of `censReg1` and `censReg2` methods relative to `best` method for beta153year equal to -0.02, -0.04, -0.08, -0.16, respectively.   

```{r chunk26b}

plot_grid(plot_all_censReg_mse_beta002_sd03_cprop03_niter10000, plot_all_censReg_mse_beta004_sd03_cprop03_niter10000, plot_all_censReg_mse_beta008_sd03_cprop03_niter10000, plot_all_censReg_mse_beta016_sd03_cprop03_niter10000, labels = "AUTO")
```

Our second set of four graphs show the MSE of `subst1`, `subst2` and `subst4`  methods relative to `best` method for beta153year equal to -0.02, -0.04, -0.08, -0.16, respectively. 

```{r chunk26c}

plot_grid(plot_all_subst_mse_beta002_sd03_cprop03_niter10000, plot_all_subst_mse_beta004_sd03_cprop03_niter10000, plot_all_subst_mse_beta008_sd03_cprop03_niter10000, plot_all_subst_mse_beta016_sd03_cprop03_niter10000, labels = "AUTO")
```

Our third set of four graphs simply displays the MSE from the `subst2`, `censReg1` and `best` methods together on the same plot, which is displayed below.

```{r chunk26d}

plot_grid(plot_all_mse_beta002_sd03_cprop03_niter10000, plot_all_mse_beta004_sd03_cprop03_niter10000, plot_all_mse_beta008_sd03_cprop03_niter10000, plot_all_mse_beta016_sd03_cprop03_niter10000, labels = "AUTO")
```


##### Predictions for different values of sd28vs153

For all our predictions in this section, these parameters are fixed: cprop = 0.3,  cb153year = -0.02, whilst sd28_153 is given four values: 0.1, 0.3, 0.5 and 0.7 respectively. 

We begin by showing graphs of the variance of predictions of cb28 annual means from our chosen censoring methods.  A common feature of all these graphs is that they typically have an approximately parabolic "U" shape, with higher variance at each end of the time period than in the middle of the period.   This is in accordance with our prior expectations because this is generally the case. 

Our first set of four graphs show the variance of `censReg1` and `censReg2` methods relative to `best` method for sd28_153 equal to 0.1, 0.3, 0.5, 0.7, respectively.   

```{r chunk28}

plot_grid(plot_all_censReg_var_beta002_sd01_cprop03_niter10000, plot_all_censReg_var_beta002_sd03_cprop03_niter10000, plot_all_censReg_var_beta002_sd05_cprop03_niter10000, plot_all_censReg_var_beta002_sd07_cprop03_niter10000, labels = "AUTO")
```

Our second set of four graphs show the variance of `subst1`, `subst2` and `subst4`  methods relative to `best` method for sd28_153 equal to 0.1, 0.3, 0.5, 0.7, respectively.

```{r chunk29}

plot_grid(plot_all_subst_var_beta002_sd01_cprop03_niter10000, plot_all_subst_var_beta002_sd03_cprop03_niter10000, plot_all_subst_var_beta002_sd05_cprop03_niter10000, plot_all_subst_var_beta002_sd07_cprop03_niter10000, labels = "AUTO")
```

Our third set of four graphs simply displays the results from the `subst2`, `censReg1` and `best` methods together on the same plot, which is displayed below.

```{r chunk30}

plot_grid(plot_all_var_beta002_sd01_cprop03_niter10000, plot_all_var_beta002_sd03_cprop03_niter10000, plot_all_var_beta002_sd05_cprop03_niter10000, plot_all_var_beta002_sd07_cprop03_niter10000, labels = "AUTO")
```


We will now show graphs of the bias of predictions of cb28 annual means from our chosen censoring methods.

Our first set of four graphs show the bias of `censReg1` and `censReg2` methods relative to `best` method for sd28_153 equal to 0.1, 0.3, 0.5, 0.7, respectively.   

```{r chunk31}

plot_grid(plot_all_censReg_bias_beta002_sd01_cprop03_niter10000, plot_all_censReg_bias_beta002_sd03_cprop03_niter10000, plot_all_censReg_bias_beta002_sd05_cprop03_niter10000, plot_all_censReg_bias_beta002_sd07_cprop03_niter10000, labels = "AUTO")
```

Our second set of four graphs show the bias of `subst1`, `subst2` and `subst4`  methods relative to `best` method for sd28_153 equal to 0.1, 0.3, 0.5, 0.7, respectively. 

```{r chunk32}

plot_grid(plot_all_subst_bias_beta002_sd01_cprop03_niter10000, plot_all_subst_bias_beta002_sd03_cprop03_niter10000, plot_all_subst_bias_beta002_sd05_cprop03_niter10000, plot_all_subst_bias_beta002_sd07_cprop03_niter10000, labels = "AUTO")
```

Our third set of four graphs simply displays the results from the `subst2`, `censReg1` and `best` methods together on the same plot, which is displayed below.

```{r chunk33a}

plot_grid(plot_all_bias_beta002_sd01_cprop03_niter10000, plot_all_bias_beta002_sd03_cprop03_niter10000, plot_all_bias_beta002_sd05_cprop03_niter10000, plot_all_bias_beta002_sd07_cprop03_niter10000, labels = "AUTO")
```


We will now show graphs of the MSE of predictions of cb28 annual means from our chosen censoring methods.

Our first set of four graphs show the MSE of `censReg1` and `censReg2` methods relative to `best` method for sd28_153 equal to 0.1, 0.3, 0.5, 0.7, respectively.   

```{r chunk33b}

plot_grid(plot_all_censReg_mse_beta002_sd01_cprop03_niter10000, plot_all_censReg_mse_beta002_sd03_cprop03_niter10000, plot_all_censReg_mse_beta002_sd05_cprop03_niter10000, plot_all_censReg_mse_beta002_sd07_cprop03_niter10000, labels = "AUTO")
```

Our second set of four graphs show the MSE of `subst1`, `subst2` and `subst4`  methods relative to `best` method for sd28_153 equal to 0.1, 0.3, 0.5, 0.7, respectively. 

```{r chunk33c}

plot_grid(plot_all_subst_mse_beta002_sd01_cprop03_niter10000, plot_all_subst_mse_beta002_sd03_cprop03_niter10000, plot_all_subst_mse_beta002_sd05_cprop03_niter10000, plot_all_subst_mse_beta002_sd07_cprop03_niter10000, labels = "AUTO")
```

Our third set of four graphs simply displays the MSE from the `subst2`, `censReg1` and `best` methods together on the same plot, which is displayed below.

```{r chunk33d}

plot_grid(plot_all_mse_beta002_sd01_cprop03_niter10000, plot_all_mse_beta002_sd03_cprop03_niter10000, plot_all_mse_beta002_sd05_cprop03_niter10000, plot_all_mse_beta002_sd07_cprop03_niter10000, labels = "AUTO")
```



##### Predictions for different values of cprop

For all our predictions in this section, these parameters are fixed: sd28_153 = 0.5,  cb153year = -0.02, whilst cprop is given four values: 0.1, 0.3, 0.5 and 0.7 respectively. 

We begin by showing graphs of the variance of predictions of cb28 annual means from our chosen censoring methods.


Our first set of four graphs show the variance of `censReg1` and `censReg2` methods relative to `best` method for cprop equal to 0.1, 0.3, 0.5, 0.7, respectively.   

```{r chunk35}

plot_grid(plot_all_censReg_var_beta002_sd05_cprop01_niter10000, plot_all_censReg_var_beta002_sd05_cprop03_niter10000, plot_all_censReg_var_beta002_sd05_cprop05_niter10000, plot_all_censReg_var_beta002_sd05_cprop07_niter10000, labels = "AUTO")
```

Our second set of four graphs show the variance of `subst1`, `subst2` and `subst4`  methods relative to `best` method for cprop equal to 0.1, 0.3, 0.5, 0.7, respectively.

```{r chunk36}
plot_grid(plot_all_subst_var_beta002_sd05_cprop01_niter10000, plot_all_subst_var_beta002_sd05_cprop03_niter10000, plot_all_subst_var_beta002_sd05_cprop05_niter10000, plot_all_subst_var_beta002_sd05_cprop07_niter10000, labels = "AUTO")
```

Our third set of four graphs simply displays the results from the `subst2`, `censReg1` and `best` methods together on the same plot, which is displayed below. 

```{r chunk37}
plot_grid(plot_all_var_beta002_sd05_cprop01_niter10000, plot_all_var_beta002_sd05_cprop03_niter10000, plot_all_var_beta002_sd05_cprop05_niter10000, plot_all_var_beta002_sd05_cprop07_niter10000, labels = "AUTO")
```


We will now show graphs of the bias of predictions of cb28 annual means from our chosen censoring methods.

Our first set of four graphs show the bias of `censReg1` and `censReg2` methods relative to `best` method for cprop equal to 0.1, 0.3, 0.5, 0.7, respectively.   

```{r chunk38}
plot_grid(plot_all_censReg_bias_beta002_sd05_cprop01_niter10000, plot_all_censReg_bias_beta002_sd05_cprop03_niter10000, plot_all_censReg_bias_beta002_sd05_cprop05_niter10000, plot_all_censReg_bias_beta002_sd05_cprop07_niter10000, labels = "AUTO")
```

Our second set of four graphs show the bias of `subst1`, `subst2` and `subst4`  methods relative to `best` method for cprop equal to 0.1, 0.3, 0.5, 0.7, respectively. 

```{r chunk39}
plot_grid(plot_all_subst_bias_beta002_sd05_cprop01_niter10000, plot_all_subst_bias_beta002_sd05_cprop03_niter10000, plot_all_subst_bias_beta002_sd05_cprop05_niter10000, plot_all_subst_bias_beta002_sd05_cprop07_niter10000, labels = "AUTO")
```

Our third set of four graphs simply displays the results from the `subst2`, `censReg1` and `best` methods together on the same plot, which is displayed below.

```{r chunk40a}
plot_grid(plot_all_bias_beta002_sd05_cprop01_niter10000, plot_all_bias_beta002_sd05_cprop03_niter10000, plot_all_bias_beta002_sd05_cprop05_niter10000, plot_all_bias_beta002_sd05_cprop07_niter10000, labels = "AUTO")
```


We will now show graphs of the MSE of predictions of cb28 annual means from our chosen censoring methods.

Our first set of four graphs show the MSE of `censReg1` and `censReg2` methods relative to `best` method for cprop equal to 0.1, 0.3, 0.5, 0.7, respectively.   

```{r chunk40b}
plot_grid(plot_all_censReg_mse_beta002_sd05_cprop01_niter10000, plot_all_censReg_mse_beta002_sd05_cprop03_niter10000, plot_all_censReg_mse_beta002_sd05_cprop05_niter10000, plot_all_censReg_mse_beta002_sd05_cprop07_niter10000, labels = "AUTO")
```

Our second set of four graphs show the MSE of `subst1`, `subst2` and `subst4`  methods relative to `best` method for cprop equal to 0.1, 0.3, 0.5, 0.7, respectively. 

```{r chunk40c}
plot_grid(plot_all_subst_mse_beta002_sd05_cprop01_niter10000, plot_all_subst_mse_beta002_sd05_cprop03_niter10000, plot_all_subst_mse_beta002_sd05_cprop05_niter10000, plot_all_subst_mse_beta002_sd05_cprop07_niter10000, labels = "AUTO")
```

Our third set of four graphs simply displays the MSE from the `subst2`, `censReg1` and `best` methods together on the same plot, which is displayed below.

```{r chunk40d}
plot_grid(plot_all_mse_beta002_sd05_cprop01_niter10000, plot_all_mse_beta002_sd05_cprop03_niter10000, plot_all_mse_beta002_sd05_cprop05_niter10000, plot_all_mse_beta002_sd05_cprop07_niter10000, labels = "AUTO")
```



##### Predictions for low-low, high-low, low-high, high-high values of sd28vs153-cprop

We will now use the same sets of parameter values that we used in our earlier section "Selection of censoring methods for further study".  Concretely: beta28year = -0.02 is held fixed, whilst a "low" and a "high" value for each of `cprop` and `sd28_153` are used.  Concretely: (0.1, 0.1), (0.7, 0.1), (0.1, 0.5) and (0.7, 0.5) were used for (cprop, sd28_153) respectively.

We begin by showing graphs of the variance of predictions of cb28 annual means from our chosen censoring methods.


Our first set of four graphs show the variance of `censReg1` and `censReg2` methods relative to `best` method for (sd28_153, cprop) equal to (0.1, 0.1), (0.1, 0.7), (0.7, 0.1) and (0.7, 0.7), respectively.   

```{r chunk42}
plot_grid(plot_all_censReg_var_beta002_sd01_cprop01_niter10000, plot_all_censReg_var_beta002_sd01_cprop07_niter10000, plot_all_censReg_var_beta002_sd07_cprop01_niter10000, plot_all_censReg_var_beta002_sd07_cprop07_niter10000, labels = "AUTO")
```

Our second set of four graphs show the variance of `subst1`, `subst2` and `subst4`  methods relative to `best` method for (sd28_153, cprop) equal to (0.1, 0.1), (0.1, 0.7), (0.7, 0.1) and (0.7, 0.7), respectively.   

```{r chunk43}
plot_grid(plot_all_subst_var_beta002_sd01_cprop01_niter10000, plot_all_subst_var_beta002_sd01_cprop07_niter10000, plot_all_subst_var_beta002_sd07_cprop01_niter10000, plot_all_subst_var_beta002_sd07_cprop07_niter10000, labels = "AUTO")
```

Our third set of four graphs simply displays the results from the `subst2`, `censReg1` and `best` methods together on the same plot, which is displayed below.

```{r chunk44}
plot_grid(plot_all_var_beta002_sd01_cprop01_niter10000, plot_all_var_beta002_sd01_cprop07_niter10000, plot_all_var_beta002_sd07_cprop01_niter10000, plot_all_var_beta002_sd07_cprop07_niter10000, labels = "AUTO")
```


We will now show graphs of the bias of predictions of cb28 annual means from our chosen censoring methods.

Our first set of four graphs show the bias of `censReg1` and `censReg2` methods relative to `best` method for (sd28_153, cprop) equal to (0.1, 0.1), (0.1, 0.7), (0.7, 0.1) and (0.7, 0.7), respectively.      

```{r chunk45}
plot_grid(plot_all_censReg_bias_beta002_sd01_cprop01_niter10000, plot_all_censReg_bias_beta002_sd01_cprop07_niter10000, plot_all_censReg_bias_beta002_sd07_cprop01_niter10000, plot_all_censReg_bias_beta002_sd07_cprop07_niter10000, labels = "AUTO")
```

Our second set of four graphs show the bias of `subst1`, `subst2` and `subst4`  methods relative to `best` method for (sd28_153, cprop) equal to (0.1, 0.1), (0.1, 0.7), (0.7, 0.1) and (0.7, 0.7), respectively.    

```{r chunk46}
plot_grid(plot_all_subst_bias_beta002_sd01_cprop01_niter10000, plot_all_subst_bias_beta002_sd01_cprop07_niter10000, plot_all_subst_bias_beta002_sd07_cprop01_niter10000, plot_all_subst_bias_beta002_sd07_cprop07_niter10000, labels = "AUTO")
```

Our third set of four graphs simply displays the results from the `subst2`, `censReg1` and `best` methods together on the same plot, which is displayed below.

```{r chunk47a}
plot_grid(plot_all_bias_beta002_sd01_cprop01_niter10000, plot_all_bias_beta002_sd01_cprop07_niter10000, plot_all_bias_beta002_sd07_cprop01_niter10000, plot_all_bias_beta002_sd07_cprop07_niter10000, labels = "AUTO")
```


We will now show graphs of the MSE of predictions of cb28 annual means from our chosen censoring methods.

Our first set of four graphs show the MSE of `censReg1` and `censReg2` methods relative to `best` method for (sd28_153, cprop) equal to (0.1, 0.1), (0.1, 0.7), (0.7, 0.1) and (0.7, 0.7), respectively.      

```{r chunk47b}
plot_grid(plot_all_censReg_mse_beta002_sd01_cprop01_niter10000, plot_all_censReg_mse_beta002_sd01_cprop07_niter10000, plot_all_censReg_mse_beta002_sd07_cprop01_niter10000, plot_all_censReg_mse_beta002_sd07_cprop07_niter10000, labels = "AUTO")
```

Our second set of four graphs show the MSE of `subst1`, `subst2` and `subst4`  methods relative to `best` method for (sd28_153, cprop) equal to (0.1, 0.1), (0.1, 0.7), (0.7, 0.1) and (0.7, 0.7), respectively.    

```{r chunk47c}
plot_grid(plot_all_subst_mse_beta002_sd01_cprop01_niter10000, plot_all_subst_mse_beta002_sd01_cprop07_niter10000, plot_all_subst_mse_beta002_sd07_cprop01_niter10000, plot_all_subst_mse_beta002_sd07_cprop07_niter10000, labels = "AUTO")
```

Our third set of four graphs simply displays the MSE from the `subst2`, `censReg1` and `best` methods together on the same plot, which is displayed below.

```{r chunk47d}
plot_grid(plot_all_mse_beta002_sd01_cprop01_niter10000, plot_all_mse_beta002_sd01_cprop07_niter10000, plot_all_mse_beta002_sd07_cprop01_niter10000, plot_all_mse_beta002_sd07_cprop07_niter10000, labels = "AUTO")
```
























